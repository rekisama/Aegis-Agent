#!/usr/bin/env python3
"""
è°ƒè¯•LLMå“åº”
"""

import asyncio
import json
from python.llm.deepseek_client import DeepSeekClient

async def debug_llm_response():
    """è°ƒè¯•LLMå“åº”"""
    print("ğŸ” è°ƒè¯•LLMå“åº”")
    print("=" * 40)
    
    system_prompt = """You are an intelligent task planner for an AI agent. 

Available tools: ['terminal', 'search', 'code']

For each task, analyze what tools are needed and create a step-by-step execution plan.

IMPORTANT: Respond ONLY with valid JSON, no additional text.

JSON format:
{
    "description": "Brief description of the execution plan",
    "steps": [
        {
            "tool": "tool_name",
            "parameters": {"param1": "value1", "param2": "value2"},
            "reason": "Why this tool is needed"
        }
    ]
}

Tool parameters:
- search: {"query": "search term", "max_results": 5}
- terminal: {"command": "system command"}
- code: {"code": "python code to execute"}

Examples:
For "æœç´¢æœ€è¿‘ä¿é™©æ–°é—»":
{
    "description": "Search for recent insurance news",
    "steps": [
        {
            "tool": "search",
            "parameters": {"query": "æœ€è¿‘ä¿é™©æ–°é—»", "max_results": 5},
            "reason": "Need to search for recent insurance news"
        }
    ]
}

For "æŸ¥çœ‹å½“å‰ç›®å½•æ–‡ä»¶":
{
    "description": "List files in current directory",
    "steps": [
        {
            "tool": "terminal",
            "parameters": {"command": "dir"},
            "reason": "Need to list files in current directory"
        }
    ]
}

Be specific and practical. For search tasks, extract the search query from the task description."""

    prompt = "Task: æŸ¥çœ‹å½“å‰ç›®å½•æ–‡ä»¶\n\nTask Analysis: {'complexity': 'simple', 'requires_delegation': False, 'required_tools': [], 'estimated_duration': 'short'}\n\nCreate an execution plan:"
    
    try:
        async with DeepSeekClient() as llm_client:
            result = await llm_client.generate_response(
                prompt=prompt,
                system_prompt=system_prompt,
                temperature=0.3,
                max_tokens=800
            )
            
            print(f"âœ… LLMå“åº”æˆåŠŸ: {result['success']}")
            print(f"ğŸ“ å“åº”å†…å®¹:")
            print("-" * 40)
            print(result['content'])
            print("-" * 40)
            
            # å°è¯•è§£æJSON
            try:
                parsed = json.loads(result['content'])
                print(f"âœ… JSONè§£ææˆåŠŸ!")
                print(f"ğŸ“‹ è§£æç»“æœ: {json.dumps(parsed, indent=2, ensure_ascii=False)}")
            except json.JSONDecodeError as e:
                print(f"âŒ JSONè§£æå¤±è´¥: {e}")
                print(f"ğŸ” å°è¯•æ¸…ç†å“åº”...")
                
                # å°è¯•æ¸…ç†å“åº”
                content = result['content'].strip()
                if content.startswith('```json'):
                    content = content[7:]
                if content.endswith('```'):
                    content = content[:-3]
                content = content.strip()
                
                print(f"ğŸ§¹ æ¸…ç†åçš„å†…å®¹:")
                print(content)
                
                try:
                    parsed = json.loads(content)
                    print(f"âœ… æ¸…ç†åJSONè§£ææˆåŠŸ!")
                except json.JSONDecodeError as e2:
                    print(f"âŒ æ¸…ç†åä»ç„¶è§£æå¤±è´¥: {e2}")
                    
    except Exception as e:
        print(f"âŒ LLMè¯·æ±‚å¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(debug_llm_response()) 