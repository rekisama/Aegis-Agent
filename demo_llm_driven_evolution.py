#!/usr/bin/env python3
"""
LLM-Driven Self-Evolution Demo
LLM é©±åŠ¨çš„è‡ªè¿›åŒ–æ¼”ç¤º
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½åˆ†æã€åˆ†ç±»å’Œæ¨è
"""

import asyncio
import logging
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from python.agent.self_evolving_core import create_self_evolving_agent
from python.agent.core import AgentConfig


async def demo_llm_driven_analysis():
    """æ¼”ç¤º LLM é©±åŠ¨çš„åˆ†æåŠŸèƒ½"""
    
    print("ğŸ§  LLM-Driven Self-Evolution Demo")
    print("=" * 50)
    
    # åˆ›å»ºè‡ªè¿›åŒ– Agent
    config = AgentConfig(
        name="LLM-Evolving Agent",
        model="deepseek-chat",
        temperature=0.7,
        max_tokens=4000,
        memory_enabled=True,
        hierarchical_enabled=True,
        tools_enabled=True
    )
    
    agent = create_self_evolving_agent(config)
    
    print(f"ğŸ¤– Created LLM-driven agent: {agent.config.name}")
    
    # æ¼”ç¤ºä¸åŒç±»å‹çš„ä»»åŠ¡
    demo_tasks = [
        "æœç´¢æœ€æ–°çš„ AI å‘å±•è¶‹åŠ¿",
        "è®¡ç®— 25 * 13 + 47 çš„ç»“æœ",
        "åˆ†æå½“å‰ç›®å½•çš„æ–‡ä»¶ç»“æ„",
        "ç»Ÿè®¡å­—ç¬¦ä¸² 'Hello World' ä¸­å­—æ¯çš„æ•°é‡",
        "æŸ¥æ‰¾ Python ç¼–ç¨‹æœ€ä½³å®è·µ",
        "åˆ›å»ºä¸€ä¸ªç®€å•çš„æ–‡æœ¬å¤„ç†å·¥å…·"
    ]
    
    print("\nğŸ“‹ Executing tasks with LLM-driven analysis...")
    print("-" * 50)
    
    for i, task in enumerate(demo_tasks, 1):
        print(f"\nğŸ”§ Task {i}: {task}")
        
        try:
            # æ‰§è¡Œä»»åŠ¡
            result = await agent.execute_task(task)
            
            # æ˜¾ç¤ºç»“æœæ‘˜è¦
            status = result.get("status", "unknown")
            result_content = result.get("result", "")[:100]
            print(f"âœ… Status: {status}")
            print(f"ğŸ“ Result: {result_content}...")
            
            # æ˜¾ç¤º LLM åˆ†æä¿¡æ¯
            if "metadata" in result:
                metadata = result["metadata"]
                if "tool_results" in metadata:
                    tools_used = [r["tool"] for r in metadata["tool_results"]]
                    print(f"ğŸ› ï¸  Tools used: {', '.join(tools_used)}")
            
        except Exception as e:
            print(f"âŒ Error: {e}")
    
    # è·å–è¿›åŒ–æŠ¥å‘Š
    print("\nğŸ“Š LLM-Driven Evolution Report")
    print("-" * 50)
    
    evolution_report = await agent.get_evolution_report()
    
    if "error" not in evolution_report:
        metrics = evolution_report.get("evolution_metrics", {})
        print(f"ğŸ“ˆ Total Tasks: {metrics.get('total_tasks', 0)}")
        print(f"ğŸ¯ Success Rate: {metrics.get('success_rate', 0.0):.1%}")
        print(f"â±ï¸  Avg Execution Time: {metrics.get('average_execution_time', 0.0):.2f}s")
        print(f"ğŸ› ï¸  Tools Created: {metrics.get('tools_created', 0)}")
        print(f"ğŸ“š Improvement Score: {metrics.get('improvement_score', 0.0):.1%}")
        
        # æ˜¾ç¤º LLM ç”Ÿæˆçš„å»ºè®®
        recommendations = evolution_report.get("recommendations", [])
        if recommendations:
            print("\nğŸ’¡ LLM-Generated Recommendations:")
            for rec in recommendations:
                print(f"   â€¢ {rec}")
    
    # æ¼”ç¤º LLM é©±åŠ¨çš„å·¥å…·åˆ›å»º
    print("\nğŸ› ï¸  LLM-Driven Tool Creation Demo")
    print("-" * 50)
    
    # åˆ›å»ºä¸€ä¸ªåŸºäº LLM åˆ†æçš„å·¥å…·
    tool_name = "smart_text_analyzer"
    tool_description = "Intelligent text analysis with LLM-driven insights"
    tool_code = """
# LLM é©±åŠ¨çš„æ–‡æœ¬åˆ†æå·¥å…·
text = params.get('text', '')
analysis_type = params.get('analysis_type', 'basic')

if analysis_type == 'basic':
    result = f"Text length: {len(text)}, Word count: {len(text.split())}"
elif analysis_type == 'sentiment':
    # è¿™é‡Œå¯ä»¥é›†æˆ LLM è¿›è¡Œæƒ…æ„Ÿåˆ†æ
    result = "Sentiment analysis: Neutral (placeholder)"
elif analysis_type == 'complexity':
    # æ–‡æœ¬å¤æ‚åº¦åˆ†æ
    words = text.split()
    avg_word_length = sum(len(word) for word in words) / len(words) if words else 0
    result = f"Average word length: {avg_word_length:.2f}"
else:
    result = f"Unknown analysis type: {analysis_type}"
"""
    tool_parameters = {
        "text": {"type": "string", "description": "Text to analyze", "required": True},
        "analysis_type": {"type": "string", "description": "Type of analysis", "required": False, "default": "basic"}
    }
    
    success = await agent.create_dynamic_tool(tool_name, tool_description, tool_code, tool_parameters)
    
    if success:
        print(f"âœ… Created LLM-driven tool: {tool_name}")
        print(f"ğŸ“ Description: {tool_description}")
        print(f"âš™ï¸  Parameters: {len(tool_parameters)} parameters")
    else:
        print(f"âŒ Failed to create LLM-driven tool: {tool_name}")
    
    # æ‰§è¡Œè¿›åŒ–è¿‡ç¨‹
    print("\nğŸ”„ LLM-Driven Evolution Process")
    print("-" * 50)
    
    evolution_result = await agent.evolve()
    
    if evolution_result.get("evolution_completed"):
        evolution_score = evolution_result.get("evolution_score", 0.0)
        print(f"âœ… Evolution completed with score: {evolution_score:.1%}")
        
        improvements = evolution_result.get("improvements_made", [])
        if improvements:
            print("ğŸ“ˆ LLM-Suggested Improvements:")
            for improvement in improvements:
                print(f"   â€¢ {improvement}")
        
        new_capabilities = evolution_result.get("new_capabilities", [])
        if new_capabilities:
            print("ğŸ†• New Capabilities:")
            for capability in new_capabilities:
                print(f"   â€¢ {capability}")
    else:
        print(f"âŒ Evolution failed: {evolution_result.get('error', 'Unknown error')}")
    
    # æœ€ç»ˆçŠ¶æ€
    print("\nğŸ“Š Final LLM-Driven Evolution Status")
    print("-" * 50)
    
    final_status = agent.get_evolution_status()
    print(f"ğŸ¤– Agent: {final_status.get('evolution_enabled', False)}")
    print(f"ğŸ“š Learning: {final_status.get('learning_enabled', False)}")
    print(f"ğŸ”„ Reflection: {final_status.get('reflection_enabled', False)}")
    
    metrics = final_status.get("metrics", {})
    print(f"ğŸ“ˆ Total Tasks: {metrics.get('total_tasks', 0)}")
    print(f"ğŸ¯ Success Rate: {metrics.get('success_rate', 0.0):.1%}")
    print(f"ğŸ› ï¸  Tools Created: {metrics.get('tools_created', 0)}")
    
    capabilities = final_status.get("capabilities", {})
    print("\nğŸ”§ LLM-Enhanced Capabilities:")
    for capability, enabled in capabilities.items():
        status = "âœ…" if enabled else "âŒ"
        print(f"   {status} {capability}")
    
    print("\nğŸ‰ LLM-Driven Self-Evolution Demo Completed!")
    print("=" * 50)


async def demo_llm_analysis_comparison():
    """æ¼”ç¤º LLM åˆ†æä¸ä¼ ç»Ÿæ–¹æ³•çš„å¯¹æ¯”"""
    
    print("\nğŸ” LLM Analysis vs Traditional Methods")
    print("=" * 50)
    
    from python.agent.adaptive_learning import adaptive_learning
    
    # æµ‹è¯•ä»»åŠ¡
    test_tasks = [
        "æœç´¢ Python æœºå™¨å­¦ä¹ æ•™ç¨‹",
        "è®¡ç®—å¤æ‚çš„æ•°å­¦å…¬å¼",
        "åˆ†æç³»ç»Ÿæ€§èƒ½æ•°æ®",
        "åˆ›å»ºè‡ªå®šä¹‰æ•°æ®å¤„ç†å·¥å…·"
    ]
    
    for task in test_tasks:
        print(f"\nğŸ“ Task: {task}")
        
        # ä¼ ç»Ÿæ–¹æ³•ï¼ˆå…³é”®è¯åŒ¹é…ï¼‰
        traditional_recommendations = adaptive_learning.get_recommendations(task)
        print(f"ğŸ”§ Traditional: {traditional_recommendations.get('recommended_tools', [])}")
        
        # LLM æ–¹æ³•
        llm_recommendations = await adaptive_learning.get_llm_recommendations(task)
        print(f"ğŸ§  LLM-Driven: {llm_recommendations.get('recommended_tools', [])}")
        print(f"ğŸ’¡ Reasoning: {llm_recommendations.get('reasoning', 'No reasoning')}")
        print(f"ğŸ“Š Success Probability: {llm_recommendations.get('estimated_success_probability', 0.0):.1%}")


async def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    try:
        # LLM é©±åŠ¨çš„è‡ªè¿›åŒ–æ¼”ç¤º
        await demo_llm_driven_analysis()
        
        # LLM åˆ†æå¯¹æ¯”æ¼”ç¤º
        await demo_llm_analysis_comparison()
        
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        logging.error(f"Demo error: {e}")


if __name__ == "__main__":
    asyncio.run(main()) 