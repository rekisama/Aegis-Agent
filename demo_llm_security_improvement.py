#!/usr/bin/env python3
"""
LLM Security Validation Improvement Demo
LLM å®‰å…¨éªŒè¯æ”¹è¿›æ¼”ç¤º
å±•ç¤ºä»ç¡¬ç¼–ç æ£€æµ‹åˆ° LLM æ™ºèƒ½æ£€æµ‹çš„æ”¹è¿›
"""

import asyncio
import logging
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from python.agent.self_evolving_core import create_self_evolving_agent
from python.agent.core import AgentConfig


async def demo_security_improvement():
    """æ¼”ç¤ºå®‰å…¨éªŒè¯çš„æ”¹è¿›"""
    
    print("ğŸ”’ LLM Security Validation Improvement Demo")
    print("=" * 50)
    
    # åˆ›å»º Agent
    config = AgentConfig(name="Security Agent")
    agent = create_self_evolving_agent(config)
    
    print(f"ğŸ¤– Created security agent: {agent.config.name}")
    
    # æµ‹è¯•ä»£ç æ ·æœ¬
    test_cases = [
        {
            "name": "Safe with os import",
            "code": """
# This code imports os but doesn't use it dangerously
import os
text = params.get('text', '')
result = f"Text length: {len(text)}"
""",
            "description": "å¯¼å…¥ os ä½†ä¸å±é™©ä½¿ç”¨"
        },
        
        {
            "name": "Dangerous os usage",
            "code": """
# This code uses os dangerously
import os
command = params.get('command', 'ls')
result = os.system(command)
""",
            "description": "å±é™©åœ°ä½¿ç”¨ os.system"
        },
        
        {
            "name": "Safe calculation",
            "code": """
# Safe calculation
numbers = params.get('numbers', [])
result = sum(numbers) if numbers else 0
""",
            "description": "å®‰å…¨çš„æ•°å­¦è®¡ç®—"
        },
        
        {
            "name": "Safe with format",
            "code": """
# Safe string formatting
text = params.get('text', '')
formatted = f"Processed: {text}"
result = formatted.upper()
""",
            "description": "å®‰å…¨çš„å­—ç¬¦ä¸²æ ¼å¼åŒ–"
        }
    ]
    
    print("\nğŸ” Testing Security Validation Methods...")
    print("-" * 50)
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ“ Test {i}: {test_case['name']}")
        print(f"ğŸ“„ Description: {test_case['description']}")
        print("-" * 30)
        print("Code:")
        print(test_case['code'].strip())
        print("-" * 30)
        
        try:
            # æ—§æ–¹æ³•ï¼ˆç¡¬ç¼–ç æ£€æŸ¥ï¼‰
            old_result = agent._basic_security_check(test_case['code'])
            print(f"ğŸ”§ Old method (hardcoded): {'âŒ REJECT' if not old_result else 'âœ… ACCEPT'}")
            
            # æ–°æ–¹æ³•ï¼ˆLLM æ£€æŸ¥ï¼‰
            new_result = await agent._validate_generated_code(test_case['code'])
            print(f"ğŸ§  New method (LLM): {'âŒ REJECT' if not new_result else 'âœ… ACCEPT'}")
            
            # åˆ†ææ”¹è¿›
            if old_result != new_result:
                if new_result and not old_result:
                    print("ğŸ‰ Improvement: LLM correctly accepted safe code that was rejected by hardcoded rules")
                elif old_result and not new_result:
                    print("âš ï¸  Change: LLM rejected code that was accepted by hardcoded rules")
            else:
                print("âœ… Consistent: Both methods agree")
                
        except Exception as e:
            print(f"âŒ Error: {e}")
    
    # æ¼”ç¤ºå·¥å…·åˆ›å»º
    print("\nğŸ› ï¸  Tool Creation with LLM Security Validation")
    print("-" * 50)
    
    suggestions = [
        "å»ºè®®åˆ›å»ºä¸€ä¸ªå®‰å…¨çš„æ–‡æœ¬åˆ†æå·¥å…·",
        "éœ€è¦åˆ›å»ºä¸€ä¸ªæ•°æ®ç»Ÿè®¡å·¥å…·"
    ]
    
    for suggestion in suggestions:
        print(f"\nğŸ’¡ Suggestion: {suggestion}")
        
        try:
            await agent._analyze_tool_creation_need(suggestion)
            print("âœ… Tool creation analysis completed")
            
        except Exception as e:
            print(f"âŒ Error: {e}")
    
    print("\nğŸ“Š Summary")
    print("-" * 50)
    print("ğŸ”§ Old Method (Hardcoded):")
    print("   â€¢ åŸºäºå…³é”®è¯åŒ¹é…")
    print("   â€¢ è¿‡äºä¸¥æ ¼ï¼Œæ‹’ç»å®‰å…¨ä»£ç ")
    print("   â€¢ æ— æ³•ç†è§£ä¸Šä¸‹æ–‡")
    print("   â€¢ å®¹æ˜“è¯¯åˆ¤")
    
    print("\nğŸ§  New Method (LLM):")
    print("   â€¢ åŸºäºè¯­ä¹‰ç†è§£")
    print("   â€¢ æ™ºèƒ½åˆ†æå®‰å…¨é£é™©")
    print("   â€¢ è€ƒè™‘ä»£ç ä¸Šä¸‹æ–‡")
    print("   â€¢ æ›´å‡†ç¡®çš„åˆ¤æ–­")
    
    print("\nğŸ‰ LLM Security Validation Improvement Demo Completed!")
    print("=" * 50)


async def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    try:
        await demo_security_improvement()
        
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        logging.error(f"Demo error: {e}")


if __name__ == "__main__":
    asyncio.run(main()) 