#!/usr/bin/env python3
"""
LLM-Driven Tool Creation Demo
LLM é©±åŠ¨å·¥å…·åˆ›å»ºæ¼”ç¤º
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ LLM åˆ†æå»ºè®®å¹¶è‡ªåŠ¨åˆ›å»ºæ–°å·¥å…·
"""

import asyncio
import logging
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from python.agent.self_evolving_core import create_self_evolving_agent
from python.agent.core import AgentConfig


async def demo_llm_tool_creation():
    """æ¼”ç¤º LLM é©±åŠ¨çš„å·¥å…·åˆ›å»º"""
    
    print("ğŸ› ï¸  LLM-Driven Tool Creation Demo")
    print("=" * 50)
    
    # åˆ›å»ºè‡ªè¿›åŒ– Agent
    config = AgentConfig(
        name="Tool Creator Agent",
        model="deepseek-chat",
        temperature=0.7,
        max_tokens=4000,
        memory_enabled=True,
        hierarchical_enabled=True,
        tools_enabled=True
    )
    
    agent = create_self_evolving_agent(config)
    
    print(f"ğŸ¤– Created tool creator agent: {agent.config.name}")
    
    # æ¼”ç¤ºä¸åŒç±»å‹çš„å»ºè®®
    demo_suggestions = [
        "å»ºè®®åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æƒ…æ„Ÿåˆ†æå·¥å…·ï¼Œå¯ä»¥åˆ†æç”¨æˆ·è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘",
        "éœ€è¦åˆ›å»ºä¸€ä¸ªæ•°æ®å¯è§†åŒ–å·¥å…·ï¼Œèƒ½å¤Ÿç”Ÿæˆç®€å•çš„å›¾è¡¨",
        "åº”è¯¥åˆ›å»ºä¸€ä¸ªæ–‡ä»¶æ ¼å¼è½¬æ¢å·¥å…·ï¼Œæ”¯æŒä¸åŒæ ¼å¼ä¹‹é—´çš„è½¬æ¢",
        "å»ºè®®æ”¹è¿›ç°æœ‰çš„æœç´¢åŠŸèƒ½ï¼Œä¸éœ€è¦åˆ›å»ºæ–°å·¥å…·",
        "éœ€è¦åˆ›å»ºä¸€ä¸ªæ—¶é—´ç®¡ç†å·¥å…·ï¼Œå¸®åŠ©ç”¨æˆ·å®‰æ’ä»»åŠ¡",
        "å»ºè®®åˆ›å»ºä¸€ä¸ªè¯­è¨€ç¿»è¯‘å·¥å…·ï¼Œæ”¯æŒå¤šè¯­è¨€ç¿»è¯‘"
    ]
    
    print("\nğŸ“‹ Testing LLM tool creation analysis...")
    print("-" * 50)
    
    for i, suggestion in enumerate(demo_suggestions, 1):
        print(f"\nğŸ’¡ Suggestion {i}: {suggestion}")
        
        try:
            # æ¨¡æ‹Ÿåæ€å»ºè®®å¤„ç†
            await agent._handle_reflection_suggestions({
                "suggestions": [suggestion]
            })
            
            print("âœ… Suggestion processed")
            
        except Exception as e:
            print(f"âŒ Error processing suggestion: {e}")
    
    # æ¼”ç¤ºç›´æ¥å·¥å…·åˆ›å»º
    print("\nğŸ› ï¸  Direct LLM Tool Creation Demo")
    print("-" * 50)
    
    # æµ‹è¯• LLM ä»£ç ç”Ÿæˆ
    test_tool_name = "smart_calculator"
    test_tool_description = "Advanced calculator with mathematical expression evaluation"
    test_parameters = {
        "expression": {"type": "string", "description": "Mathematical expression to evaluate", "required": True},
        "precision": {"type": "integer", "description": "Decimal precision", "required": False, "default": 2}
    }
    
    print(f"ğŸ”§ Testing code generation for: {test_tool_name}")
    
    try:
        # ç”Ÿæˆå·¥å…·ä»£ç 
        tool_code = await agent._generate_tool_code(
            test_tool_name, 
            test_tool_description, 
            test_parameters, 
            "Evaluate mathematical expressions safely"
        )
        
        print("âœ… Code generation successful")
        print(f"ğŸ“ Generated code length: {len(tool_code)} characters")
        print("ğŸ“„ Code preview:")
        print("-" * 30)
        print(tool_code[:200] + "..." if len(tool_code) > 200 else tool_code)
        print("-" * 30)
        
        # éªŒè¯ä»£ç å®‰å…¨æ€§
        is_safe = agent._validate_generated_code(tool_code)
        print(f"ğŸ”’ Code safety validation: {'âœ… PASS' if is_safe else 'âŒ FAIL'}")
        
        # åˆ›å»ºå·¥å…·
        success = await agent.create_dynamic_tool(
            test_tool_name, 
            test_tool_description, 
            tool_code, 
            test_parameters
        )
        
        if success:
            print(f"âœ… Successfully created tool: {test_tool_name}")
        else:
            print(f"âŒ Failed to create tool: {test_tool_name}")
            
    except Exception as e:
        print(f"âŒ Tool creation failed: {e}")
    
    # æ¼”ç¤ºå¤æ‚å·¥å…·åˆ›å»º
    print("\nğŸ”¬ Complex Tool Creation Demo")
    print("-" * 50)
    
    complex_suggestions = [
        "å»ºè®®åˆ›å»ºä¸€ä¸ªæ™ºèƒ½æ–‡æœ¬æ‘˜è¦å·¥å…·ï¼Œèƒ½å¤Ÿè‡ªåŠ¨æå–æ–‡ç« çš„å…³é”®ä¿¡æ¯",
        "éœ€è¦åˆ›å»ºä¸€ä¸ªæ•°æ®æ¸…æ´—å·¥å…·ï¼Œèƒ½å¤Ÿå¤„ç†å„ç§æ ¼å¼çš„æ•°æ®æ–‡ä»¶",
        "å»ºè®®åˆ›å»ºä¸€ä¸ªä»£ç è´¨é‡åˆ†æå·¥å…·ï¼Œæ£€æŸ¥ä»£ç çš„å¤æ‚åº¦å’Œå¯è¯»æ€§"
    ]
    
    for suggestion in complex_suggestions:
        print(f"\nğŸ’¡ Complex suggestion: {suggestion}")
        
        try:
            # åˆ†æå·¥å…·åˆ›å»ºéœ€æ±‚
            await agent._analyze_tool_creation_need(suggestion)
            
        except Exception as e:
            print(f"âŒ Error: {e}")
    
    # è·å–å·¥å…·ç»Ÿè®¡
    print("\nğŸ“Š Tool Creation Statistics")
    print("-" * 50)
    
    from python.agent.dynamic_tool_creator import dynamic_tool_creator
    
    stats = dynamic_tool_creator.get_tool_statistics()
    print(f"ğŸ“¦ Total Dynamic Tools: {stats.get('total_dynamic_tools', 0)}")
    print(f"ğŸ“Š Total Usage: {stats.get('total_usage', 0)}")
    print(f"ğŸ¯ Average Success Rate: {stats.get('average_success_rate', 0.0):.1%}")
    
    tools_list = stats.get("tools", [])
    if tools_list:
        print("\nğŸ› ï¸  Created Tools:")
        for tool in tools_list:
            print(f"   â€¢ {tool['name']}: {tool['usage_count']} uses, {tool['success_rate']:.1%} success")
    
    print("\nğŸ‰ LLM-Driven Tool Creation Demo Completed!")
    print("=" * 50)


async def demo_llm_analysis_comparison():
    """æ¼”ç¤º LLM åˆ†æä¸ä¼ ç»Ÿæ–¹æ³•çš„å¯¹æ¯”"""
    
    print("\nğŸ” LLM vs Traditional Tool Creation Analysis")
    print("=" * 50)
    
    # åˆ›å»º Agent
    config = AgentConfig(name="Comparison Agent")
    agent = create_self_evolving_agent(config)
    
    # æµ‹è¯•å»ºè®®
    test_suggestions = [
        "å»ºè®®åˆ›å»ºä¸€ä¸ªæ–°çš„æœç´¢å·¥å…·",
        "éœ€è¦æ”¹è¿›ç°æœ‰å·¥å…·çš„æ€§èƒ½",
        "å»ºè®®åˆ›å»ºä¸€ä¸ªæ•°æ®åˆ†æå·¥å…·",
        "åº”è¯¥ä¼˜åŒ–ä»£ç æ‰§è¡Œæ•ˆç‡"
    ]
    
    for suggestion in test_suggestions:
        print(f"\nğŸ“ Suggestion: {suggestion}")
        
        # ä¼ ç»Ÿæ–¹æ³•ï¼ˆç®€å•å…³é”®è¯åŒ¹é…ï¼‰
        traditional_result = "create" in suggestion.lower() or "new" in suggestion.lower()
        print(f"ğŸ”§ Traditional analysis: {'Create tool' if traditional_result else 'No action'}")
        
        # LLM æ–¹æ³•ï¼ˆæ™ºèƒ½åˆ†æï¼‰
        try:
            # è¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿ LLM åˆ†æç»“æœ
            print(f"ğŸ§  LLM analysis: Intelligent analysis would be performed")
            print(f"ğŸ’¡ LLM would consider: tool necessity, implementation feasibility, etc.")
        except Exception as e:
            print(f"âŒ LLM analysis failed: {e}")


async def demo_safety_validation():
    """æ¼”ç¤ºä»£ç å®‰å…¨æ€§éªŒè¯"""
    
    print("\nğŸ”’ Code Safety Validation Demo")
    print("=" * 50)
    
    config = AgentConfig(name="Safety Agent")
    agent = create_self_evolving_agent(config)
    
    # æµ‹è¯•ä»£ç æ ·æœ¬
    test_codes = [
        # å®‰å…¨ä»£ç 
        """
# Safe code
text = params.get('text', '')
result = f"Processed text: {len(text)} characters"
""",
        # å±é™©ä»£ç 
        """
# Dangerous code
import os
result = os.system(params.get('command', 'ls'))
""",
        # è¾¹ç•Œæƒ…å†µ
        """
# Edge case
eval(params.get('expression', '1+1'))
""",
        # æ­£å¸¸ä»£ç 
        """
# Normal code
numbers = params.get('numbers', [])
result = sum(numbers) if numbers else 0
"""
    ]
    
    for i, code in enumerate(test_codes, 1):
        print(f"\nğŸ” Testing code sample {i}:")
        print("-" * 30)
        print(code.strip())
        print("-" * 30)
        
        is_safe = agent._validate_generated_code(code)
        print(f"ğŸ”’ Safety validation: {'âœ… PASS' if is_safe else 'âŒ FAIL'}")
        
        if not is_safe:
            print("âš ï¸  Dangerous patterns detected!")


async def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    try:
        # LLM é©±åŠ¨å·¥å…·åˆ›å»ºæ¼”ç¤º
        await demo_llm_tool_creation()
        
        # åˆ†æå¯¹æ¯”æ¼”ç¤º
        await demo_llm_analysis_comparison()
        
        # å®‰å…¨æ€§éªŒè¯æ¼”ç¤º
        await demo_safety_validation()
        
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        logging.error(f"Demo error: {e}")


if __name__ == "__main__":
    asyncio.run(main()) 