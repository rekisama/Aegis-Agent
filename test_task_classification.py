#!/usr/bin/env python3
"""
Task Classification Test
æµ‹è¯•ä»»åŠ¡åˆ†ç±»çš„ä¿®å¤æ•ˆæœ
"""

import asyncio
import logging
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(str(Path(__file__).parent))


async def test_task_classification():
    """æµ‹è¯•ä»»åŠ¡åˆ†ç±»æ˜¯å¦è¿˜æœ‰ç¡¬ç¼–ç é—®é¢˜"""
    
    print("ğŸ§ª Task Classification Test")
    print("=" * 50)
    print("æµ‹è¯•ä»»åŠ¡åˆ†ç±»æ˜¯å¦å®Œå…¨ç”± LLM è‡ªä¸»åˆ¤æ–­")
    print("=" * 50)
    
    from python.agent.self_evolving_core import TaskAnalyzer
    
    # æµ‹è¯•ç”¨ä¾‹ï¼šè¿™äº›ä»»åŠ¡åº”è¯¥è¢«æ­£ç¡®åˆ†ç±»ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç ä¸º "search"
    test_tasks = [
        "ä¸œäº¬ç°åœ¨å‡ ç‚¹äº†",
        "åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·", 
        "è®¡ç®— 123 * 456 çš„ç»“æœ",
        "å¸®æˆ‘å†™ä¸€ä¸ªPythonå‡½æ•°",
        "åˆ†æè¿™ä¸ªæ•°æ®é›†",
        "ç¿»è¯‘è¿™å¥è¯",
        "åˆ›å»ºä¸€ä¸ªæ—¶é—´å·¥å…·"
    ]
    
    for i, task in enumerate(test_tasks, 1):
        print(f"\nğŸ” Test {i}: {task}")
        print("-" * 50)
        
        try:
            # æµ‹è¯•ä»»åŠ¡åˆ†ç±»
            analysis = await TaskAnalyzer.analyze_task(task, "task_type")
            task_type = analysis.get("task_type", "unknown")
            
            print(f"ğŸ“Š Task Type: {task_type}")
            
            # æ£€æŸ¥æ˜¯å¦è¢«é”™è¯¯åˆ†ç±»ä¸º search
            if task_type == "search":
                print("âš ï¸  WARNING: Task might be incorrectly classified as 'search'")
                print("   This could lead to using search tools instead of specialized tools")
            elif task_type in ["time", "weather", "calculation", "programming", "analysis", "translation", "custom"]:
                print("âœ… GOOD: Task correctly classified with specific type")
            else:
                print(f"â„¹ï¸  INFO: Task classified as '{task_type}'")
                
        except Exception as e:
            print(f"âŒ Test failed: {e}")
            import traceback
            traceback.print_exc()
    
    print("\nğŸ‰ Task Classification Test Completed!")
    print("=" * 50)


async def test_tool_creation_decision():
    """æµ‹è¯•å·¥å…·åˆ›å»ºå†³ç­–æ˜¯å¦å®Œå…¨ç”± LLM åˆ¤æ–­"""
    
    print("\nğŸ› ï¸  Tool Creation Decision Test")
    print("=" * 50)
    print("æµ‹è¯•å·¥å…·åˆ›å»ºå†³ç­–æ˜¯å¦å®Œå…¨ç”± LLM è‡ªä¸»åˆ¤æ–­")
    print("=" * 50)
    
    from python.agent.self_evolving_core import TaskAnalyzer
    
    # æµ‹è¯•ç”¨ä¾‹ï¼šè¿™äº›ä»»åŠ¡åº”è¯¥è§¦å‘å·¥å…·åˆ›å»º
    test_tasks = [
        "ä¸œäº¬ç°åœ¨å‡ ç‚¹äº†",  # åº”è¯¥åˆ›å»ºæ—¶é—´å·¥å…·
        "åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·",   # åº”è¯¥åˆ›å»ºå¤©æ°”å·¥å…·
        "è®¡ç®— 123 * 456",  # åº”è¯¥åˆ›å»ºè®¡ç®—å·¥å…·
        "å¸®æˆ‘å†™ä¸€ä¸ªPythonå‡½æ•°",  # åº”è¯¥åˆ›å»ºç¼–ç¨‹å·¥å…·
        "åˆ†æè¿™ä¸ªæ•°æ®é›†",   # åº”è¯¥åˆ›å»ºåˆ†æå·¥å…·
    ]
    
    for i, task in enumerate(test_tasks, 1):
        print(f"\nğŸ” Test {i}: {task}")
        print("-" * 50)
        
        try:
            # æµ‹è¯•å·¥å…·åˆ›å»ºå†³ç­–
            analysis = await TaskAnalyzer.analyze_task(task, "tool_creation")
            
            should_create = analysis.get("should_create_tool", False)
            tool_name = analysis.get("tool_name", "")
            reasoning = analysis.get("reasoning", "")
            
            print(f"ğŸ“Š Should create tool: {should_create}")
            
            if should_create:
                print(f"ğŸ› ï¸  Tool name: {tool_name}")
                print(f"ğŸ’¡ Reasoning: {reasoning}")
                print("âœ… GOOD: LLM decided to create specialized tool")
            else:
                print(f"ğŸ’¡ Reasoning: {reasoning}")
                print("â„¹ï¸  INFO: LLM decided not to create tool")
                
        except Exception as e:
            print(f"âŒ Test failed: {e}")
            import traceback
            traceback.print_exc()
    
    print("\nğŸ‰ Tool Creation Decision Test Completed!")
    print("=" * 50)


async def test_full_execution_with_classification():
    """æµ‹è¯•å®Œæ•´æ‰§è¡Œæµç¨‹ä¸­çš„ä»»åŠ¡åˆ†ç±»"""
    
    print("\nğŸš€ Full Execution with Classification Test")
    print("=" * 50)
    print("æµ‹è¯•å®Œæ•´æ‰§è¡Œæµç¨‹ä¸­çš„ä»»åŠ¡åˆ†ç±»å’Œå·¥å…·åˆ›å»º")
    print("=" * 50)
    
    from python.agent.self_evolving_core import SelfEvolvingAgent
    from python.agent.core import AgentConfig
    
    config = AgentConfig(
        name="Classification Test Agent",
        model="deepseek-chat",
        temperature=0.7,
        max_tokens=4000,
        memory_enabled=True,
        hierarchical_enabled=True,
        tools_enabled=True
    )
    
    agent = SelfEvolvingAgent(config)
    
    test_task = "ä¸œäº¬ç°åœ¨å‡ ç‚¹äº†"
    
    print(f"ğŸ” Executing task: {test_task}")
    print("-" * 50)
    
    try:
        # æ‰§è¡Œä»»åŠ¡
        result = await agent.execute_task(test_task)
        
        print(f"âœ… Task completed")
        print(f"ğŸ“Š Result: {result.get('result', 'No result')}")
        
        # æ£€æŸ¥æ˜¯å¦åˆ›å»ºäº†æ—¶é—´å·¥å…·
        from python.agent.dynamic_tool_creator import dynamic_tool_creator
        stats = dynamic_tool_creator.get_tool_statistics()
        tools = stats.get("tools", [])
        
        if tools:
            print(f"ğŸ› ï¸  Dynamic tools available: {len(tools)}")
            for tool in tools[-1:]:  # åªæ˜¾ç¤ºæœ€æ–°åˆ›å»ºçš„å·¥å…·
                print(f"   â€¢ {tool['name']}: {tool['description']}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ—¶é—´ç›¸å…³çš„å·¥å…·
                if "time" in tool['name'].lower() or "æ—¶é—´" in tool['description']:
                    print("âœ… SUCCESS: Time tool was created correctly")
                else:
                    print("âš ï¸  WARNING: Tool might not be time-specific")
        else:
            print("â„¹ï¸  No new dynamic tools created")
            
    except Exception as e:
        print(f"âŒ Execution failed: {e}")
        import traceback
        traceback.print_exc()
    
    print("\nğŸ‰ Full Execution Test Completed!")
    print("=" * 50)


async def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    try:
        await test_task_classification()
        await test_tool_creation_decision()
        await test_full_execution_with_classification()
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        logging.error(f"Test error: {e}")


if __name__ == "__main__":
    asyncio.run(main()) 